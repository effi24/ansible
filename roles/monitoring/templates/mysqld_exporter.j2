{{ ansible_managed | comment }}

### Set the command-line arguments to pass to the server.
#
# See below for a full list of available arguments.
#
# Due to shell scaping, to pass backslashes for regexes, you need to double
# them (\\d for \d). If running under systemd, you need to double them again
# (\\\\d to mean \d), and escape newlines too.
ARGS="
{%- for collector in mysqld_exporter_enabled_collectors -%}
{%-   if not collector is mapping -%}
    --collect.{{ collector }} \
{%   else -%}
{%     set name, options = (collector.items()|list)[0] %}
    --collect.{{ name }} \
{%     for k,v in options|dictsort %}
    --collect.{{ name }}.{{ k }}={{ v | quote }} \
{%     endfor -%}
{%   endif -%}
{% endfor %}
--web.listen-address={{ mysqld_exporter_web_listen_address }}
--config.my-cnf=/etc/.exporter.cnf"


### Database authentication
#
# By default the DATABASE connection string will be read from
# the file specified with the -config.my-cnf parameter.  For example:
# ARGS='--config.my-cnf /etc/mysql/debian.cnf'
#
# Note that SSL options can only be set using a cnf file.

# To set a connection string from the environment instead, set the
# DATA_SOURCE_NAME variable.

# To use UNIX domain sockets authentication with or without password:
# DATA_SOURCE_NAME="prometheus:nopassword@unix(/run/mysqld/mysqld.sock)/"
# DATA_SOURCE_NAME="prometheus@unix(/run/mysqld/mysqld.sock)/"

# To use a TCP connection and password authentication:
# DATA_SOURCE_NAME="prometheus:password@(hostname:port)/dbname"

### Monitoring user creation.
#
# You need a user with enough privileges for the exporter to run.
#
# Example to create a user to connect (only) via UNIX socket:
#   CREATE USER IF NOT EXISTS 'prometheus'@'localhost' IDENTIFIED WITH auth_socket;
#
# To create a user with a password, that can log in via UNIX or TCP sockets:
#   CREATE USER IF NOT EXISTS 'prometheus'@'localhost' IDENTIFIED BY 'password';
#
# Finally, to grant the necessary privileges:
#   GRANT PROCESS, REPLICATION CLIENT, SELECT ON *.* TO 'prometheus'@'localhost';

### Availabe command-line arguments to pass to the exporter.
#
# General options:

#  --config.my-cnf="${HOME}/.my.cnf"
#      Path to .my.cnf file to read MySQL credentials from.
#  --exporter.lock_wait_timeout=2
#      Set a lock_wait_timeout on the connection to avoid long metadata
#      locking.
#  --exporter.log_slow_filter
#      Add a log_slow_filter to avoid slow query logging of scrapes.
#      NOTE: Not supported by Oracle MySQL.
#  --log.level="info"
#      Only log messages with the given severity or above.
#      Valid levels: [debug, info, warn, error, fatal].
#  --log.format="logger:stderr"
#      Set the log target and format.
#      Example: "logger:syslog?appname=bob&local=7" or
#      "logger:stdout?json=true"
#  --timeout-offset=0.25
#      Offset to subtract from timeout in seconds.
#  --web.listen-address=":9104"
#      Address to listen on for web interface and telemetry.
#  --web.telemetry-path="/metrics"
#      Path under which to expose metrics.

# Collectior options:

#  --collect.auto_increment.columns
#      Collect auto_increment columns and max values from information_schema.
#  --collect.binlog_size
#      Collect the current size of all registered binlog files.

#  --collect.engine_innodb_status
#      Collect from SHOW ENGINE INNODB STATUS.

#  --collect.engine_tokudb_status
#      Collect from SHOW ENGINE TOKUDB STATUS.

#  --collect.global_status
#      Collect from SHOW GLOBAL STATUS.

#  --collect.global_variables
#      Collect from SHOW GLOBAL VARIABLES.

#  --collect.heartbeat
#      Collect from heartbeat.
#  --collect.heartbeat.database="heartbeat"
#      Database from where to collect heartbeat data.
#  --collect.heartbeat.table="heartbeat"
#      Table from where to collect heartbeat data.

#  --collect.info_schema.clientstats
#      If running with userstat=1, set to true to collect client statistics.

#  --collect.info_schema.innodb_cmp
#      Collect metrics from information_schema.innodb_cmp.

#  --collect.info_schema.innodb_cmpmem
#      Collect metrics from information_schema.innodb_cmpmem.

#  --collect.info_schema.innodb_metrics
#      Collect metrics from information_schema.innodb_metrics.

#  --collect.info_schema.innodb_tablespaces
#      Collect metrics from information_schema.innodb_sys_tablespaces.

#  --collect.info_schema.processlist
#      Collect current thread state counts from the
#      information_schema.processlist.
#  --collect.info_schema.processlist.min_time=0
#      Minimum time a thread must be in each state to be counted.
#  --collect.info_schema.processlist.processes_by_host
#      Enable collecting the number of processes by host.
#  --collect.info_schema.processlist.processes_by_user
#      Enable collecting the number of processes by user.

#  --collect.info_schema.query_response_time
#      Collect query response time distribution if query_response_time_stats is
#      ON..

#  --collect.info_schema.schemastats
#      If running with userstat=1, set to true to collect schema statistics.

#  --collect.info_schema.tables
#      Collect metrics from information_schema.tables.
#  --collect.info_schema.tables.databases="*"
#      The list of databases to collect table stats for, or '*' for all.

#  --collect.info_schema.tablestats
#      If running with userstat=1, set to true to collect table statistics.

#  --collect.info_schema.userstats
#      If running with userstat=1, set to true to collect user statistics.

#  --collect.mysql.user
#      Collect data from mysql.user
#  --collect.mysql.user.privileges
#      Enable collecting user privileges from mysql.user.

#  --collect.perf_schema.eventsstatements
#      Collect metrics from
#      performance_schema.events_statements_summary_by_digest.
#  --collect.perf_schema.eventsstatements.digest_text_limit=120
#      Maximum length of the normalized statement text.
#  --collect.perf_schema.eventsstatements.limit=250
#      Limit the number of events statements digests by response time.
#  --collect.perf_schema.eventsstatements.timelimit=86400
#      Limit how old the 'last_seen' events statements can be, in seconds.

#  --collect.perf_schema.eventsstatementssum
#      Collect metrics of grand sums from
#      performance_schema.events_statements_summary_by_digest.

#  --collect.perf_schema.eventswaits
#      Collect metrics from
#      performance_schema.events_waits_summary_global_by_event_name.

#  --collect.perf_schema.file_events
#      Collect metrics from performance_schema.file_summary_by_event_name.

#  --collect.perf_schema.file_instances
#      Collect metrics from performance_schema.file_summary_by_instance.
#  --collect.perf_schema.file_instances.filter=".*"
#      RegEx file_name filter for performance_schema.file_summary_by_instance.
#  --collect.perf_schema.file_instances.remove_prefix="/var/lib/mysql/"
#      Remove path prefix in performance_schema.file_summary_by_instance.

#  --collect.perf_schema.indexiowaits
#      Collect metrics from
#      performance_schema.table_io_waits_summary_by_index_usage.

#  --collect.perf_schema.replication_applier_status_by_worker
#      Collect metrics from
#      performance_schema.replication_applier_status_by_worker.

#  --collect.perf_schema.replication_group_member_stats
#      Collect metrics from performance_schema.replication_group_member_stats.

#  --collect.perf_schema.tableiowaits
#      Collect metrics from performance_schema.table_io_waits_summary_by_table.

#  --collect.perf_schema.tablelocks
#      Collect metrics from
#      performance_schema.table_lock_waits_summary_by_table.

#  --collect.slave_hosts
#      Scrape information from 'SHOW SLAVE HOSTS'.

#  --collect.slave_status
#      Collect from SHOW SLAVE STATUS.